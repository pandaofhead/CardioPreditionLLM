
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Cardiovascular Disease Risk Prediction: Explanation Framework</title>
            <style>
                body {
                    font-family: Arial, sans-serif;
                    line-height: 1.6;
                    max-width: 1200px;
                    margin: 0 auto;
                    padding: 20px;
                }
                h1, h2, h3 {
                    color: #2c3e50;
                }
                img {
                    max-width: 100%;
                    height: auto;
                    display: block;
                    margin: 20px auto;
                }
                pre {
                    background-color: #f5f5f5;
                    padding: 15px;
                    border-radius: 5px;
                    overflow-x: auto;
                }
                table {
                    border-collapse: collapse;
                    width: 100%;
                    margin: 20px 0;
                }
                th, td {
                    border: 1px solid #ddd;
                    padding: 8px;
                    text-align: left;
                }
                th {
                    background-color: #f2f2f2;
                }
            </style>
        </head>
        <body>
            <h1>Cardiovascular Disease Risk Prediction: Explanation Framework</h1>
<p>Generated on: 2025-04-27 21:58:18</p>
<h2>Executive Summary</h2>
<p>This report presents the results of our cardiovascular disease (CVD) risk prediction explanation framework. The framework combines traditional machine learning models with large language models (LLMs) to provide comprehensive, actionable explanations for CVD risk predictions.</p>
<p>The framework includes:
1. <strong>Counterfactual Explanations</strong>: 'What-if' scenarios showing how changes in risk factors might affect risk
2. <strong>Clinical Interpretations</strong>: Clear, non-technical explanations of the model's predictions
3. <strong>Guideline-Aligned Explanations</strong>: Recommendations aligned with established medical guidelines
4. <strong>Integrated Explanations</strong>: Comprehensive explanations combining all three approaches</p>
<h2>Evaluation Results</h2>
<h3>Summary Statistics</h3>
<pre><code>Evaluation Summary for counterfactual Explanations
==================================================

Clinical Relevance:
  Mean: 9.80
  Std: 0.45
  Min: 9.00
  Max: 10.00
  Median: 10.00

Actionability:
  Mean: 9.50
  Std: 0.71
  Min: 8.50
  Max: 10.00
  Median: 10.00

Completeness:
  Mean: 9.20
  Std: 0.45
  Min: 9.00
  Max: 10.00
  Median: 9.00

Clarity:
  Mean: 10.00
  Std: 0.00
  Min: 10.00
  Max: 10.00
  Median: 10.00

Guideline Alignment:
  Mean: 8.60
  Std: 1.14
  Min: 7.00
  Max: 10.00
  Median: 9.00

</code></pre>
<h3>Visualizations</h3>
<h4>Criterion Scores</h4>
<p><img alt="Criterion Scores" src="criterion_scores.png" /></p>
<h4>Mean Scores</h4>
<p><img alt="Mean Scores" src="mean_scores.png" /></p>
<h4>Criterion Heatmap</h4>
<p><img alt="Criterion Heatmap" src="criterion_heatmap.png" /></p>
<h4>Radar Plot</h4>
<p><img alt="Radar Plot" src="radar_plot.png" /></p>
<h2>Integrated Explanations</h2>
<p>The integrated explanations combine counterfactual, clinical, and guideline-aligned approaches to provide comprehensive, actionable insights for healthcare providers.</p>
<h2>Methodology</h2>
<h3>Explanation Generation Process</h3>
<ol>
<li><strong>Feature Importance Analysis</strong>: SHAP values are extracted from trained Random Forest and XGBoost models</li>
<li><strong>Counterfactual Explanations</strong>: Generated using LLM to provide 'what-if' scenarios</li>
<li><strong>Clinical Interpretations</strong>: Created to explain model predictions in clear, non-technical language</li>
<li><strong>Guideline-Aligned Explanations</strong>: Developed to align with established medical guidelines</li>
<li><strong>Integrated Explanations</strong>: Combined all three explanation types into comprehensive insights</li>
</ol>
<h3>Evaluation Framework</h3>
<p>Explanations were evaluated based on the following criteria:</p>
<ol>
<li><strong>Medical Accuracy</strong>: Does the explanation accurately reflect current medical knowledge?</li>
<li><strong>Clinical Relevance</strong>: Is the explanation relevant to the patient's specific condition?</li>
<li><strong>Actionability</strong>: Does the explanation provide clear, actionable recommendations?</li>
<li><strong>Completeness</strong>: Does the explanation cover all relevant aspects of the patient's condition?</li>
<li><strong>Clarity</strong>: Is the explanation clear, well-structured, and easy to understand?</li>
<li><strong>Guideline Alignment</strong>: Does the explanation align with established medical guidelines?</li>
</ol>
<h2>Conclusions</h2>
<p>The cardiovascular disease risk prediction explanation framework demonstrates the potential of combining traditional machine learning models with large language models to provide comprehensive, actionable explanations for healthcare providers.</p>
<p>Key findings:
1. The framework successfully generates multiple types of explanations for CVD risk predictions
2. Integrated explanations provide comprehensive, actionable insights
3. Evaluation results show high scores across all criteria, particularly in clarity and actionability
4. The framework aligns well with established medical guidelines</p>
<p>Future work will focus on:
1. Expanding the framework to include more explanation types
2. Improving guideline alignment and medical accuracy
3. Conducting user studies with healthcare providers
4. Integrating the framework into clinical decision support systems</p>
        </body>
        </html>
        